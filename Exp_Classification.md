# [E-01]Classification
## 목차

-프로젝트에서 사용한 라이브러리

-프로젝트 1: 손글씨 분류하기

-프로젝트 2: 와인 분류하기

-프로젝트 3: 유방암 여부 진단하기

회고

-----------

## 루브릭 평가기준

1. 세 가지 데이터셋의 구성을 파악하고, 데이터를 이해하는 과정이 포함되어있는가?

    feature와 label 선정을 위한 데이터 분석과정을 전개함.

2. 세 가지 데이터셋에 대해 각각 5가지 모델을 이용하여 학습을 수행하고 결과값을 얻었는가?

    모델학습 및 테스트가 정상적으로 수행되고, 결과값을 얻었음.

3. 세 가지 데이터셋에 대해 모델의 평가 지표를 선택하고, 그 이유를 근거를 바탕으로 서술하였는가?

    모델학습을 통해 얻은 결과물을 바탕으로 평가지표를 선택하고, 본인의 의견을 서술하였음.

-----------

## 프로젝트에서 사용한 라이브러리

#### scikit-learn

데이터셋을 학습시키기 위해 scikit-learn 라이브러리를 가져왔다. 여기에는 우리가 연습을 위해 사용할 데이터셋, 머신러닝을 위한 모델들, 학습한 모델을 테스트하고 그 결과를 보여줄 수 있는 도구들을 제공한다.

특히 이번 실습에서는 Decision Tree, Random Forest, SVM, SGD Classifier, Logistic Regression 이렇게 5개의 내장된 모델을 사용하고 비교한다.

-------------

## 프로젝트 1: 손글씨 분류하기

### 데이터 파악하기

우선 우리가 분류하려는 데이터셋에 대해 알기 위해  

print(digits.target_names)  
print(digits.DESCR)  

이 두 가지를 먼저 실행해보았다.

그 결과 이 데이터가 0\~9 까지의 숫자를 손글씨로 쓴 것을 이미지로 데이터화한 것임을 알았다. 데이터의 타겟은 글씨로 쓴 숫자이며, 이를 8×8 크기의 이미지로 만들었으고 각 영역에는 0~16의 숫자가 들어간다. 이 이미지를 일렬로 64개의 배열로 쭉 늘어놓은 것이 바로 data 이다. 각각의 타겟 데이터는 약 180개의 샘플이 존재해 총 1797개의 데이터 샘플이 들어있다.

### 모델 학습하고 평가하기

data를 feature로, target을 label로 두고 5가지 모델을 학습시켜 그 결과를 보았다. 이 때 test set은 전체 데이터셋의 20%이다.

학습을 위해 사용한 모델은 Decision Tree, Random Forest, SVM, SGD Classifier, Logistic Regression이다.

글씨를 분류함에 있어서 거짓 음성도, 거짓 양성도 최소화해야한다. 0이 아닌 숫자를 0으로 인식하거나, 0을 다른 숫자로 인식해서는 안 되며 둘 다 중요한 문제이다.  
따라서 모델을 평가할 때 정밀도와 재현률 이 두 요소를 모두 고려할 수 있는 F1 스코어를 사용하는 것이 좋다.  
test set은 무작위로 선정되는데 각 타겟의 테스트 타겟이 그리 많지 않으므로 support의 차이가 상대적으로 조금 있다. 그러므로 F1 스코어의 weighted avg 값을 보고 모델을 평가하기로 했다.

Decision Tree, Random Forest, SVM, SGD Classifier, Logistic Regression의 F1 스코어값은 순서대로

0.85, 0.97, 0.98, 0.94, 0.96 이었다.

Decision Tree 모델보다 다른 4가지 모델들이 분류를 더 잘하고 있음을 알 수 있었으며 그 중에서는 대동소이하지만 SVM 모델이 가장 효과가 좋다는 것을 알 수 있었다.

--------------------

## 프로젝트 2: 와인 분류하기

### 데이터 파악하기

우선 우리가 분류하려는 데이터셋에 대해 알기 위해  

print(wine.target_names)  
print(wine.DESCR)  

이 두 가지를 먼저 실행해보았다.

이 데이터셋은 Class_0, Class_1, Class_2 세 종류의 와인을 13가지 항목의 특징들을 가지고 분류해놓은 것이다. scikit-learn 사이트에 따르면 각각 59,71,48개로 총합 178개의 데이터 샘플이 들어있다고 한다.

### 모델 학습하고 평가하기

마찬가지로 13개 항목의 컬럼을 feature로, target class를 label로 두고 5가지 모델을 학습시켜 그 결과를 보았다. test set은 전체 데이터셋의 20%이다.

학습을 위해 사용한 모델은 Decision Tree, Random Forest, SVM, SGD Classifier, Logistic Regression이다.

와인을 분류할 때에 정밀도와 재현률 모두 고려해야하므로 손글씨와 마찬가지로 F1 스코어값을 사용하는 것이 좋다.  
test set은 무작위로 선정되는데 처음 데이터셋에서부터 각 타겟 데이터의 수의 차이가 크므로 weighted avg 값을 보고 모델을 평가하기로 했다.

Decision Tree, Random Forest, SVM, Logistic Regression의 F1 스코어값은 순서대로  

0.86, 1.00, 0.70, 0.95 였다.

SGD Classifier 모델은 실행할 때마다 값이 크게 변해 3회 실시하여 측정했다. 각각  

0.58, 0.68, 0.63이 나왔는데 다른 모델에 비해 분류 성능이 좋지 못 했으며 심지어 Class_2를 아예 분류해내지 못하는 경우도 많았다.

wine dataset을 분류하는 데에는 Random Forest가 가장 성능이 좋았으며 Logistic Regression이 뒤를 이었다.

여기서 SVM과 SGD Classifier가 손글씨 분류에서 했던 것과는 달리 매우 낮은 성능을 보이고 있으며 특히 SGD Classifier는 Class_2를 분류하지 못 하기도 하는 등의 문제가 발생했다.

우선 SVM의 경우 제대로 학습하기 위해서는 여러개의 데이터 조합을 테스트할 필요가 있으며 이를 위해서 많은 양의 데이터셋이 필요하다. 그러나 와인 분류에서 우리가 가진 데이터셋은 178개 뿐이 되지 않는다. 따라서 정확한 예측을 위해 필요한 데이터의 갯수에 미치지 못 했으며 이로 인해 낮은 성능을 내고 있다.

SGD Classifier는 여러가지 문제가 발생하는 경우가 있는데 여기에서는 가중치 스케일에 대한 문제로 보인다. 데이터셋을 들여다보면 다양한 항목들이 있는데 이것들이 와인을 분류할 때 가중치가 차이가 나게 되면 함수의 기울기의 방향이 최솟값으로 향하는 방향과 차이가 발생하게 된다. 원래 기울기의 방향이 최솟값의 방향임을 이용한 모델이기 때문에 발생한 문제로 보인다. 따라서 이 와인 데이터셋에서 사용하기에는 적합하지 않은 모델임을 알 수 있었다.

------------------

## 프로젝트 3: 유방암 여부 진단하기

### 데이터 파악하기

우리가 분류하는 데이터셋에 대해 알기 위해

print(breast_cancer.target_names)
print(breast_cancer.DESCR)

이 두 가지를 먼저 실행해보았다.

이 데이터셋은 569개의 케이스에 대해 유방암 악성과 양성으로 분류해 진단한다. 이를 위해 30가지의 속성을 사용한다. scikit-learn 사이트에 따르면 212개의 악성과 357개의 양성으로 나뉜다고 한다.

### 모델 학습하고 평가하기

30개 항목의 컬럼 feature로, 악성 여부를 label로 두고 5가지 모델을 학습시켜 그 결과를 보았다. test set은 전체 데이터셋의 20%이다.

학습을 위해 사용한 모델은 Decision Tree, Random Forest, SVM, SGD Classifier, Logistic Regression이다.

유방암의 여부를 진단하는 데에는 환자를 양성으로 오진하는 일은 없어야만 한다. 따라서 가장 중요한 평가 척도는 재현률이다. 재현률(recall)을 통해 악성인 환자가 주어졌을 때 얼마나 잘 악성으로 분류하는데 성공했는지를 알 수 있다.

악성인 데이터샘플과 양성인 데이터 샘플의 수가 차이가 크므로 recall의 weighted avg를 보자. 

Decision Tree, Random Forest, SVM, SGD Classifier, Logistic Regression의 recall값은 순서대로  

0.94, 0.97, 0.94, 0.92, 0.96 이다.

결과에서 큰 차이는 없지만 Random Forest모델이 가장 재현률이 높았으며 그 뒤를 Logistic Regression이 이었다.

위의 와인 분류 데이터셋보다도 더 많은 분류항목을 가지고 있으나 SGD Classifier 모델에서 문제가 발생하지 않았다.  F1 스코어를 비교해봐도 0.9 이상의 높은 기록을 보여주었다. 이는 와인과는 달리 신체부위의 데이터를 사용하면서 각 항목들이 비슷한 가중치를 가지고 있기 때문으로 보인다. 

--------------------

## 회고

이번 실습에서는 Decision Tree, Random Forest, SVM, SGD Classifier, Logistic Regression 이렇게 5개의 모델을 가지고 머신러닝을 진행했다.  
각각의 모델마다 다른 특징과 장단점을 가지고 있다. Random Forest는 원리상 다수의 Decision Tree를 중첩하여 작동하기 때문에 그 성능이 하나의 Decision Tree보다 더 좋았으며 데이터에 따라 SVM과 SGD Classifier는 성능이 크게 떨어진다는 것을 확인할 수 있었다.  
따라서 앞으로도 어떤 데이터를 사용하느냐에 따라 사용해야할 모델이 달라짐을 알 수 있었다. 특히 주어진 데이터가 많느냐 적느냐, 또는 컬럼으로 나눠진 항목들이 서로 독립적인가 상관관계가 있느냐에 따라서 이런 큰 차이를 보인다는 점이 흥미로웠다.  
이번에는 Random Forest와 Logisitic Regression 모델이 잘 작동했으나 이 모델들에도 단점이 존재할 것이다.

모델을 사용하고 그 성능을 평가할 때 어떤 평가지표를 볼 것인가는 그 모델의 용도와 데이터에 따라 달리 해야한다. 정밀도와 재현률을 기본으로 하여 평가를 하는데 손글씨 분류와 와인 분류에 있어서는 이 두가지를 모두 균형있게 평가할 수 있는 지표인 F1 스코어를 사용했다.  
그러나 환자 진단처럼 정밀도와 재현률 중 하나가 특히 더 중요한 경우엔 그 쪽을 중점으로 평가하여야한다. 유방암 여부 진단에서는 환자가 아닌 사람을 환자로 잘못 평가하더라도, 환자를 환자가 아니라고 실수하는 경우는 없어야하므로 재현률을 평가지표로 삼았다.

위에서 보았듯이 머신러닝을 잘 하기 위해서는 데이터와 그 용도를 잘 이해하고 파악해야한다. 그리고 어떤 모델을 적용할 것인가, 어떤 평가지표로 모델을 평가할 것인가가 매우 중요하다고 할 수 있다.  
데이터셋에 따라 어떤 모델은 비효율적일 수 있고, 어떤 모델은 특히 효율적일 수 있다. 또한 평가지표를 잘 적용해야 가장 나은 모델을 선택하고 얼마나 학습이 필요한지 알 수 있다.

머신러닝을 위한 다양한 모델과 방법론이 존재하는 만큼 어떤 모델을 선택해야하는지 결정하는 것은 아주 중요하다. 또한 이번 실습에서는 평가지표만을 가지고 모델을 찾았으나 실제로는 얼마나 많인 메모리와 시간이 필요한가 또한 중요한 요소이다. 무한한 메모리와 시간이 주어진다면 좋겠지만 당연히 이는 제한된 자원이므로 효율적인 모델을 찾아야한다는 점은 당연한 일이다.

-------------------

### Reference

https://muzukphysics.tistory.com/135  
https://gooopy.tistory.com/67  
https://deep-learning-study.tistory.com/156  
https://blog.naver.com/jinp7/222641379117  
https://zephyrus1111.tistory.com/233  

